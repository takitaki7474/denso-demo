{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, out=2):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.fc1 = nn.Linear(4*4*64, 500)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(500, out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) #  32*32*3 -> 32*32*16\n",
    "        x = F.max_pool2d(x, 2, 2) #  32*32*16 -> 16*16*16\n",
    "        x = F.relu(self.conv2(x)) #  16*16*16 -> 16*16*32\n",
    "        x = F.max_pool2d(x, 2, 2) # 16*16*32 -> 8*8*32\n",
    "        x = F.relu(self.conv3(x)) #  8*8*32 -> 8*8*64\n",
    "        x = F.max_pool2d(x, 2, 2) #  8*8*64 -> 4*4*64\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習とテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import List, Tuple, TypeVar\n",
    "\n",
    "class TrainLogging:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.log = []\n",
    "\n",
    "    def stack(self, **kwargs):\n",
    "        self.log.append(kwargs)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(self.log, f, indent=4)\n",
    "\n",
    "\n",
    "def process(trainloader, testloader, model, epochs: int, lr: float, lr_scheduling=None, log_savepath=None):\n",
    "\n",
    "    log_dict = defaultdict(list)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    if lr_scheduling is not None:\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduling)\n",
    "\n",
    "    def train(trainloader) -> Tuple[float, float]:\n",
    "        sum_loss, sum_correct, sum_dataN = 0.0, 0, 0\n",
    "        for (inputs, labels) in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            sum_dataN += labels.size(0)\n",
    "            sum_correct += (predicted == labels).sum().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = sum_loss*trainloader.batch_size/len(trainloader.dataset)\n",
    "        train_acc = float(sum_correct/sum_dataN)\n",
    "        return train_loss, train_acc\n",
    "\n",
    "    def test(testloader) -> Tuple[float, float]:\n",
    "        sum_loss, sum_correct, sum_dataN = 0.0, 0, 0\n",
    "        for (inputs, labels) in testloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            sum_dataN += labels.size(0)\n",
    "            sum_correct += (predicted == labels).sum().item()\n",
    "        test_loss = sum_loss*testloader.batch_size/len(testloader.dataset)\n",
    "        test_acc = float(sum_correct/sum_dataN)\n",
    "        return test_loss, test_acc\n",
    "\n",
    "    print(\"\\n{0:<13}{1:<13}{2:<13}{3:<13}{4:<13}{5:<6}\".format(\"epoch\",\"train/loss\",\"train/acc\",\"test/loss\",\"test/acc\",\"lr\"))\n",
    "    logging = TrainLogging()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_acc = train(trainloader)\n",
    "        test_loss, test_acc = test(testloader)\n",
    "        lr = optimizer.param_groups[-1][\"lr\"]\n",
    "        print(\"{0:<13}{1:<13.5f}{2:<13.5f}{3:<13.5f}{4:<13.5f}{5:<6.6f}\".format(epoch, train_loss, train_acc, test_loss, test_acc, lr))\n",
    "        logging.stack(epoch=epoch, train_loss=train_loss, train_acc=train_acc, test_loss=test_loss, test_acc=test_acc, lr=lr)\n",
    "        if lr_scheduling is not None: scheduler.step()\n",
    "    if log_savepath is not None:\n",
    "        logging.save(log_savepath)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 画像データの読み込みと学習データの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_dir, imsize=(32,32), img_name=False):\n",
    "    dataset = []\n",
    "    num_label = 2\n",
    "    loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n",
    "    for label in range(num_label):\n",
    "        path = os.path.join(dataset_dir, str(label), \"*.jpg\")\n",
    "        files = glob.glob(path)\n",
    "        for file in files:\n",
    "            img = Image.open(file)\n",
    "            img = loader(img)\n",
    "            if img_name:\n",
    "                img_name = file.split(\"/\")[-1]\n",
    "                dataset.append((img, label, img_name))\n",
    "            else:\n",
    "                dataset.append((img, label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(dataset_dir=\"../demo/data/train_data\")\n",
    "test = load_dataset(dataset_dir=\"../demo/data/test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch        train/loss   train/acc    test/loss    test/acc     lr    \n",
      "1            0.69449      0.48000      0.77340      0.52000      0.010000\n",
      "2            0.68945      0.56000      0.77054      0.52000      0.010000\n",
      "3            0.69363      0.52500      0.78207      0.46000      0.010000\n",
      "4            0.67496      0.62000      0.76714      0.50000      0.010000\n",
      "5            0.66429      0.60000      0.78069      0.50000      0.010000\n",
      "6            0.68582      0.57500      0.78147      0.56000      0.010000\n",
      "7            0.69212      0.54500      0.83639      0.48000      0.010000\n",
      "8            0.65874      0.60500      0.79007      0.44000      0.010000\n",
      "9            0.65422      0.58000      0.78153      0.48000      0.010000\n",
      "10           0.62399      0.66000      0.89487      0.42000      0.010000\n"
     ]
    }
   ],
   "source": [
    "model = LeNet(2)\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "model = process(trainloader, testloader, model, epochs, lr, log_savepath=\"./assets/log.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex. 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "test = load_dataset(dataset_dir=\"../demo/data/test_data\", img_name=True)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "unpredictable = []\n",
    "for (inputs, labels, img_name) in testloader:\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = outputs.max(1)\n",
    "    unpredictable += list(np.array(list(img_name))[predicted != labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_13.jpg', '1_7.jpg', '0_7.jpg', '1_5.jpg', '1_2.jpg', '1_1.jpg', '1_4.jpg', '1_23.jpg', '0_11.jpg', '1_0.jpg', '0_3.jpg', '1_9.jpg', '1_14.jpg', '1_22.jpg', '1_15.jpg', '0_20.jpg', '1_16.jpg', '1_19.jpg', '1_13.jpg', '0_5.jpg', '1_11.jpg', '0_17.jpg', '1_21.jpg', '0_23.jpg', '1_17.jpg', '1_12.jpg', '0_14.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(unpredictable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ログの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_log(path: str):\n",
    "\n",
    "    def load_losses(path: str) -> Tuple[List[float], List[float]]:\n",
    "        with open(path) as f:\n",
    "            logs = json.load(f)\n",
    "        train_losses, test_losses = [], []\n",
    "        for log in logs:\n",
    "            train_losses.append(log[\"train_loss\"])\n",
    "            test_losses.append(log[\"test_loss\"])\n",
    "        return train_losses, test_losses\n",
    "\n",
    "    def load_accs(path: str) -> Tuple[List[float], List[float]]:\n",
    "        with open(path) as f:\n",
    "            logs = json.load(f)\n",
    "        train_accs, test_accs = [], []\n",
    "        for log in logs:\n",
    "            train_accs.append(log[\"train_acc\"])\n",
    "            test_accs.append(log[\"test_acc\"])\n",
    "        return train_accs, test_accs\n",
    "\n",
    "    train_losses, test_losses = load_losses(path)\n",
    "    train_accs, test_accs = load_accs(path)\n",
    "\n",
    "    return train_losses, test_losses, train_accs, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習結果のグラフ可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lossのplot\n",
    "def plot_loss(train_losses: List[float], test_losses: List[float], savepath: str):\n",
    "    max_axisX = len(train_losses)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(range(max_axisX), train_losses)\n",
    "    plt.plot(range(max_axisX), test_losses, c='#ed7700')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train/loss', 'test/loss'])\n",
    "    plt.grid()\n",
    "    plt.savefig(savepath)\n",
    "    plt.clf()\n",
    "\n",
    "# accuracyのplot\n",
    "def plot_acc(train_accs: List[float], test_accs: List[float], savepath: str):\n",
    "    max_axisX = len(train_accs)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(range(max_axisX), train_accs)\n",
    "    plt.plot(range(max_axisX), test_accs, c='#ed7700')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['train/acc', 'test/acc'])\n",
    "    plt.grid()\n",
    "    plt.savefig(savepath)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ex. 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe62eebdac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe62eddff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses, test_losses, train_accs, test_accs = load_train_log(path=\"./assets/log.json\")\n",
    "plot_loss(train_losses, test_losses, savepath=\"./assets/loss.png\")\n",
    "plot_acc(train_accs, test_accs, savepath=\"./assets/accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
